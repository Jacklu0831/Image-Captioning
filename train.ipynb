{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image_captioning_train.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rKr-GObpbAMP","colab_type":"text"},"source":["# Image Captioning\n","\n","Keywords: CV, NLP, LSTM, attention (soft), MS-COCO, image processing, InceptionV3.\n","\n","Implementation similar to [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044)."]},{"cell_type":"code","metadata":{"id":"HHA1pG6UZRYY","colab_type":"code","colab":{}},"source":["# mount drive for both input and output\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# code\n","from caption import *\n","from model import *\n","\n","# miscellaneous\n","import numpy as np\n","from collections import Counter\n","import h5py\n","import json\n","import time\n","from tqdm import tqdm\n","from nltk.translate.bleu_score import corpus_bleu\n","\n","# PyTorch\n","import torch\n","import torch.optim\n","from torch.optim import Adam\n","import torch.utils.data as data\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","import torchvision.transforms as transforms\n","from torch.nn.utils.rnn import pack_padded_sequence\n","\n","# computing environment\n","assert torch.cuda.is_available()\n","device = torch.device('cuda')\n","cudnn.benchmark = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dVnc-iPXHcwL","colab_type":"code","colab":{}},"source":["# PARAMETERS\n","\n","# dir\n","# input_dir = 'drive/My Drive/img_cap/processed_input/' # input directory (processed data)\n","input_dir = 'processed_input/'\n","output_dir = \"drive/My Drive/img_cap/model/\" # save model directory\n","trained_model = None   # path to pre-trained model, if there is any\n","\n","# model\n","emb_dim = 512       # word embedding dimension\n","att_dim = 512       # attention dimension/size\n","dec_dim = 512       # decoder RNN/LSTM dimension\n","\n","# training\n","enc_lr = 1e-4       # encoder learning rate\n","dec_lr = 4e-4       # decoder learning rate\n","batch_size = 16     # batch size, the destroyer of all RAM\n","grad_threshold = 5. # clip gradient to prevent exploding\n","alpha_c = 1.        # regularization parameter from the paper\n","best_bleu = 0.      # highest bleu-4 score\n","log_freq = 50       # print train/val stats every number of batches\n","fine_tune = False   # determines whether to fine tune the encoder (resnet 101)\n","\n","begin_epoch = 0     # beginning epoch (resume training)\n","num_epoch = 500     # training epochs unless Colab disconnects or early stop\n","epoch_from_best = 0 # keep track of how many epochs with no improvement"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1U21dvJjyn1","colab_type":"code","colab":{}},"source":["with open(os.path.join(input_dir, \"wordmap.json\"), 'r') as f:\n","    word_map = json.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ca8rA4esVKRq","colab_type":"code","colab":{}},"source":["class StatMeter:\n","    \"\"\"\n","    Keep track of newest val, sum, count, avg.\n","    \"\"\"\n","    def __init__(self):\n","        self.reset()\n","    \n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","    \n","    def update(self, val, repeat=1):\n","        self.val = val\n","        self.sum += val * repeat\n","        self.count += repeat\n","        self.avg = self.sum / self.count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUAIB8QAVqA-","colab_type":"code","colab":{}},"source":["def lr_decay(opt, factor):\n","    \"\"\"\n","    Perform controlled learning rate decay.\n","    \"\"\"\n","    for pg in opt.param_groups:\n","        pg['lr'] *= factor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eGsetXvEWPoR","colab_type":"code","colab":{}},"source":["def accuracy(scores, targets, k):\n","    \"\"\"\n","    Compute top-k acc.\n","    \"\"\"\n","    \n","    batch_size = targets.size(0)\n","    _, idx = scores.topk(k, dim=1, largest=True, sorted=True)\n","    \n","    targets = targets.view(-1, 1).expand_as(idx)\n","    right = idx.eq(targets)\n","    \n","    # sum the right list all up\n","    right_sum = right.view(-1).float().sum()\n","    acc = right_sum.item() * (100. / batch_size)\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_j7qZtseBkH","colab_type":"code","colab":{}},"source":["def clip_gradient(optimizer, threshold):\n","    \"\"\"\n","    Clips gradients of every parameter.\n","    \"\"\"\n","    for pg in optimizer.param_groups:\n","        for p in pg['params']:\n","            if p.grad:\n","                p.grad.data.clamp_(-threshold, threshold)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmouQBB9tvFv","colab_type":"code","colab":{}},"source":["def save_model(epoch, epoch_from_best, encoder, decoder, encoder_opt, decoder_opt, best_bleu, update):\n","    \"\"\"\n","    Saves model components.\n","    \"\"\"\n","    # create state dictionary\n","    state = {'epoch':epoch, \n","             'epoch_from_best':epoch_from_best, \n","             'best_bleu':best_bleu,\n","             'encoder':encoder, \n","             'decoder':decoder, \n","             'encoder_opt':encoder_opt, \n","             'decoder_opt':decoder_opt}\n","    # save name based on whether the current is the best\n","    if update:\n","        torch.save(state, os.path.join('Drive/My Drive/img_cap/model/best_model_', epoch, '.pth.tar'))\n","    else:\n","        torch.save(state, os.path.join('Drive/My Drive/img_cap/model/model_', epoch, '.pth.tar'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mvngCAgYSyPu","colab_type":"code","colab":{}},"source":["def train(data_loader, encoder, decoder, encoder_opt, decoder_opt, criterion, epoch):\n","    \"\"\"\n","    performs an epoch of training.\n","    \"\"\"\n","    decoder.train()\n","    encoder.train()\n","    \n","    batch_time = StatMeter()   # forward + backward time by batch\n","    data_time = StatMeter()    # data loading time by batch\n","    losses = StatMeter()       # loss per word\n","    top_accs = StatMeter()     # top 5 accuracy\n","    tick = time.time()         # initialize time\n","    \n","    # each batch\n","    for i, (imgs, caps, len_caps) in enumerate(data_loader):\n","        data_time.update(time.time() - tick)\n","        \n","        # send them to GPU\n","        imgs = imgs.to(device)\n","        caps = caps.to(device)\n","        len_caps = len_caps.to(device)\n","        \n","        # forward: encode images and decode\n","        imgs = encoder(imgs)\n","        sorted_caps, decode_lengths, scores, alphas, sorted_idxs = decoder(imgs, caps, len_caps)\n","        \n","        # get targets (excluding <start>)\n","        targets = sorted_caps[:, 1:]\n","        \n","        # remove undecoded or simply pads with the PackedSequence object\n","        scores, _ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n","        targets, _ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n","\n","        # compute loss\n","        loss = criterion(scores, targets)\n","        \n","        # add regularization for soft attention (according to paper)\n","        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n","        \n","        # backward (autograd)\n","        if encoder_opt: # training encoder is very expensive\n","            encoder_opt.zero_grad()\n","        decoder_opt.zero_grad()\n","        loss.backward()\n","        \n","        # clip gradients if needed\n","        if grad_threshold:\n","            clip_gradient(decoder_opt, grad_threshold)\n","            if encoder_opt:\n","                clip_gradient(encoder_opt, grad_threshold)\n","        \n","        # update weights with optimizers\n","        decoder_opt.step()\n","        if encoder_opt:\n","            encoder_opt.step()\n","        \n","        # update metrics\n","        losses.update(loss.item(), sum(decode_lengths))\n","        top_accs.update(accuracy(scores, targets, 5), sum(decode_lengths))\n","        batch_time.update(time.time() - tick)\n","        tick = time.time()\n","    \n","        if i % log_freq == 0:\n","            print(f'E [{epoch}][{i}/{len(data_loader)}]\\t'\n","                  f'D {data_time.val:.3f}->{data_time.avg:.3f}\\t'\n","                  f'B {batch_time.val:.3f}->{batch_time.avg:.3f}\\t'\n","                  f'L {loss.val:.4f}->{loss.avg:.4f}\\t'\n","                  f'A {top_accs.val:.3f}->{top_accs.avg:.3f}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4K5w77wR86G","colab_type":"code","colab":{}},"source":["def validate(data_loader, encoder, decoder, criterion):\n","    \"\"\"\n","    Performs an epoch of validation.\n","    \"\"\"\n","    decoder.eval()\n","    if encoder:\n","        encoder.eval()\n","    \n","    # same as train() but without data loading timer\n","    batch_time = StatMeter()\n","    losses = StatMeter()\n","    top_accs = StatMeter()\n","    tick = time.time()\n","    \n","    ground_truths = []\n","    predictions = []\n","    \n","    # always disable gradient when evaluating\n","    with torch.no_grad():\n","        # all captions also passed in from caption.py\n","        for i, (imgs, caps, len_caps, all_caps) in enumerate(data_loader):\n","            # the uncommented operations are similar to train(), please refer to that\n","            imgs = imgs.to(device)\n","            caps = caps.to(device)\n","            len_caps = len_caps.to(device)\n","            \n","            if encoder:\n","                imgs = encoder(imgs)\n","\n","            sorted_caps, decode_lengths, scores, alphas, sorted_idxs = decoder(imgs, caps, len_caps)\n","            targets = sorted_caps[:, 1:]\n","            \n","            scores_cp = scores.clone() # save a copy for bleu score\n","            scores, _ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n","            targets, _ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n","            \n","            loss = criterion(scores, targets)\n","            loss += alpha_c * ((1. -  alpha.sum(dim=1)) ** 2).mean()\n","            \n","            losses.update(loss.item(), sum(decode_lengths))\n","            losses.update(loss.item(), sum(decode_lengths))\n","            top_accs.update(accuracy(scores, targets, 5), sum(decode_lengths))\n","            batch_time.update(time.time() - tick)\n","            tick = time.time()\n","            \n","            if i % log_freq == 0:\n","                print(f'V [{i}/{len(data_loader)}]\\t'\n","                      f'B {batch_time.val:.3f}->{batch_time.avg:.3f}\\t'\n","                      f'L {loss.val:.4f}->{loss.avg:.4f}\\t'\n","                      f'A {top_accs.val:.3f}->{top_accs.avg:.3f}')\n","\n","            # get ground truths (sort captions and get rid of start and end tokens)\n","            all_caps = all_caps[sorted_idxs]\n","            for j in range(all_caps.shape[0]):\n","                img_caps = all_caps[j].tolist()\n","                # get rid of <start> and <end> because they increase the bleu score\n","                img_caps = list(map(lambda cap: [w for w in cap if (w != word_map['<start>'] and w != word_map['<pad>'])], \n","                                img_caps))\n","                ground_truths.append(img_caps)\n","            \n","            # get predictions\n","            _, preds = torch.max(scores_cp, dim=2)\n","            preds = preds.tolist()\n","            temp = []\n","            for j, p in enumerate(preds):\n","                # not including pads\n","                temp.append(preds[j][:decode_lengths[j]])\n","            preds = temp\n","            predictions.extend(preds)\n","            \n","            assert len(ground_truths) == len(predictions)\n","        \n","        # use corpus_bleu library functions to calculate bleu score\n","        bleu_score = corpus_bleu(ground_truths, predictions)\n","        print(f'\\nL {loss.avg:.3f} A {top_5.avg:.3f}, B {bleu_score}\\n')\n","        \n","    return bleu_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzHJ8apJhYO1","colab_type":"code","colab":{}},"source":["def train_and_validate(trained_model=trained_model, best_bleu=best_bleu, begin_epoch=begin_epoch, \n","                       epoch_from_best=epoch_from_best, fine_tune=fine_tune, word_map=word_map):\n","    \"\"\"\n","    Train & validation pipeline.\n","    \"\"\"\n","    if trained_model:\n","        trained_model = torch.load(trained_model)\n","        begin_epoch = trained_model['epoch'] + 1\n","        epoch_from_best = trained_model['epoch_from_best']\n","        best_bleu = trained_model['best_bleu']\n","        decoder = trained_model['decoder']\n","        decoder_opt = trained_model['decoder_opt']\n","        encoder = trained_model['encoder']\n","        encoder_opt = trained_model['encoder_opt']\n","        if fine_tune and not encoder_opt:\n","            encoder.fine_tune(fine_tune)\n","            encoder_opt = Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()), lr = enc_lr)\n","    else:\n","        decoder = Decoder(len(word_map), emb_dim, dec_dim, att_dim)\n","        decoder_opt = Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()), lr = dec_lr)\n","        encoder = Encoder()\n","        encoder.fine_tune(fine_tune)\n","        if fine_tune:\n","            encoder_opt = Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()), lr = enc_lr)\n","        else:\n","            encoder_opt = None\n","        \n","    # move everything to device\n","    decoder = decoder.to(device)\n","    encoder = encoder.to(device)\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    \n","    # transform while loading data\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    \n","    # create data loaders, one worker for moving data, pin_memory for fast data transfer\n","    train_data_loader = data.DataLoader(\n","        CapData(input_dir, 'train', transform=transforms.Compose([normalize])),\n","        batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\n","    val_data_loader = data.DataLoader(\n","        CapData(input_dir, 'val', transform=transforms.Compose([normalize])),\n","        batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\n","        \n","    for epoch in range(begin_epoch, num_epoch):\n","        if epoch_from_best >= 25:\n","            break\n","        # learning rate decay every 10 epochs with no improvement\n","        if epoch_from_best % 10 == 0 and epoch_from_best != 0:\n","            if fine_tune: \n","                lr_decay(encoder_opt, 0.8)\n","            lr_decay(decoder_opt, 0.8)\n","        \n","        # train and validate\n","        train(train_data_loader, encoder, decoder, encoder_opt, decoder_opt, criterion, epoch)\n","        new_bleu = validate(val_data_loader, encoder, decoder, criterion)\n","        \n","        update = new_bleu > best_bleu\n","        if update:\n","            epoch_from_best = 0\n","            best_bleu = new_bleu\n","            print(\"New improvement!\")\n","        else:\n","            epoch_from_best += 1\n","            print(f\"No improvement for {epoch_from_best} epochs\")\n","        \n","        save_model(epoch, epoch_from_best, encoder, decoder, encoder_opt, decoder_opt, new_bleu, update)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QHh6sX5eEsci","colab_type":"text"},"source":["### Train and Validate Execution"]},{"cell_type":"code","metadata":{"id":"YFeS_J5c3xj-","colab_type":"code","colab":{}},"source":["train_and_validate()"],"execution_count":0,"outputs":[]}]}